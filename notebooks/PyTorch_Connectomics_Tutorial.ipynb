{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  PyTorch Connectomics Tutorial\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zudi-lin/pytorch_connectomics/blob/v2.0/notebooks/PyTorch_Connectomics_Tutorial.ipynb)\n",
        "\n",
        "Welcome! This notebook will help you:\n",
        "1. âœ… **Install** PyTorch Connectomics on Google Colab\n",
        "2. ğŸ¯ **Run a demo** with synthetic data\n",
        "3. ğŸ”¬ **Train** a model on real mitochondria segmentation data\n",
        "4. ğŸ“Š **Visualize** results\n",
        "\n",
        "**Time:** 15-20 minutes\n",
        "\n",
        "**GPU:** This notebook requires a GPU. Make sure to enable it:\n",
        "- Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¦ Step 1: Installation\n",
        "\n",
        "Let's install PyTorch Connectomics and its dependencies.\n",
        "\n",
        "**This takes ~2 minutes.**"
      ],
      "metadata": {
        "id": "install-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "check-gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch Connectomics\n",
        "print(\"ğŸ“¦ Installing PyTorch Connectomics...\\n\")\n",
        "\n",
        "# Clone repository\n",
        "!git clone https://github.com/zudi-lin/pytorch_connectomics.git\n",
        "%cd pytorch_connectomics\n",
        "\n",
        "# Install dependencies (pre-built packages to avoid compilation)\n",
        "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q numpy h5py cython connected-components-3d\n",
        "!pip install -q pytorch-lightning monai omegaconf\n",
        "\n",
        "# Install PyTorch Connectomics\n",
        "!pip install -q -e .\n",
        "\n",
        "print(\"\\nâœ… Installation complete!\")\n",
        "\n",
        "# Verify installation\n",
        "import torch\n",
        "import connectomics\n",
        "print(f\"\\nğŸ”§ PyTorch: {torch.__version__}\")\n",
        "print(f\"ğŸ”§ CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"ğŸ”§ PyTorch Connectomics: {connectomics.__version__}\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ Step 2: Quick Demo\n",
        "\n",
        "Let's verify the installation with a 30-second demo using synthetic data.\n",
        "\n",
        "This will:\n",
        "- Generate synthetic 3D volumes\n",
        "- Train a small 3D U-Net for 5 epochs\n",
        "- Validate the installation"
      ],
      "metadata": {
        "id": "demo-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run demo\n",
        "!python scripts/main.py --demo"
      ],
      "metadata": {
        "id": "demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¥ Step 3: Download Tutorial Data\n",
        "\n",
        "Let's download the **Lucchi++ mitochondria segmentation dataset** (~100 MB).\n",
        "\n",
        "This is real electron microscopy data with mitochondria annotations."
      ],
      "metadata": {
        "id": "data-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Lucchi++ dataset\n",
        "print(\"ğŸ“¥ Downloading Lucchi++ dataset...\\n\")\n",
        "\n",
        "!mkdir -p datasets\n",
        "!wget -q --show-progress https://huggingface.co/datasets/pytc/tutorial/resolve/main/Lucchi%2B%2B.zip\n",
        "!unzip -q Lucchi++.zip -d datasets/\n",
        "!rm Lucchi++.zip\n",
        "\n",
        "print(\"\\nâœ… Data downloaded!\")\n",
        "!ls -lh datasets/Lucchi++/"
      ],
      "metadata": {
        "id": "download-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ” Step 4: Visualize Data\n",
        "\n",
        "Let's look at the training data to understand what we're working with."
      ],
      "metadata": {
        "id": "viz-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training data\n",
        "with h5py.File('datasets/Lucchi++/train_image.h5', 'r') as f:\n",
        "    train_image = f['main'][:]\n",
        "with h5py.File('datasets/Lucchi++/train_label.h5', 'r') as f:\n",
        "    train_label = f['main'][:]\n",
        "\n",
        "print(f\"Image shape: {train_image.shape}\")\n",
        "print(f\"Label shape: {train_label.shape}\")\n",
        "print(f\"Image range: [{train_image.min():.3f}, {train_image.max():.3f}]\")\n",
        "print(f\"Mitochondria pixels: {(train_label > 0).sum() / train_label.size * 100:.1f}%\")\n",
        "\n",
        "# Visualize a slice\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "slice_idx = train_image.shape[0] // 2\n",
        "\n",
        "axes[0].imshow(train_image[slice_idx], cmap='gray')\n",
        "axes[0].set_title('EM Image (slice)')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(train_label[slice_idx], cmap='gray')\n",
        "axes[1].set_title('Mitochondria Labels')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(train_image[slice_idx], cmap='gray')\n",
        "axes[2].imshow(train_label[slice_idx], cmap='Reds', alpha=0.4)\n",
        "axes[2].set_title('Overlay')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualize-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸƒ Step 5: Train a Model\n",
        "\n",
        "Now let's train a 3D U-Net on this data!\n",
        "\n",
        "We'll use the pre-configured tutorial config and run a **fast-dev-run** first to make sure everything works."
      ],
      "metadata": {
        "id": "train-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, do a fast dev run (1 batch) to check everything works\n",
        "print(\"ğŸ”§ Running fast-dev-run (1 batch)...\\n\")\n",
        "!python scripts/main.py --config tutorials/monai_lucchi++.yaml --fast-dev-run\n",
        "\n",
        "print(\"\\nâœ… Fast-dev-run completed!\")"
      ],
      "metadata": {
        "id": "fast-dev-run"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Training (Optional)\n",
        "\n",
        "For a real training run, we'll train for fewer epochs to fit in Colab's time limits.\n",
        "\n",
        "**This takes ~10-15 minutes on a T4 GPU.**"
      ],
      "metadata": {
        "id": "full-train-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 50 epochs (reduced from 1000 for demo)\n",
        "print(\"ğŸƒ Training model (50 epochs)...\\n\")\n",
        "\n",
        "!python scripts/main.py \\\n",
        "    --config tutorials/monai_lucchi++.yaml \\\n",
        "    optimization.max_epochs=50 \\\n",
        "    system.training.batch_size=2 \\\n",
        "    data.iter_num_per_epoch=50\n",
        "\n",
        "print(\"\\nâœ… Training complete!\")"
      ],
      "metadata": {
        "id": "full-train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Š Step 6: View Training Progress\n",
        "\n",
        "Let's load and visualize the training metrics."
      ],
      "metadata": {
        "id": "metrics-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tensorboard\n",
        "!pip install -q tensorboard\n",
        "\n",
        "# Load TensorBoard\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Find the latest run\n",
        "import glob\n",
        "import os\n",
        "\n",
        "log_dirs = glob.glob('outputs/lucchi++_monai_unet/*/logs')\n",
        "if log_dirs:\n",
        "    latest_log = max(log_dirs, key=os.path.getmtime)\n",
        "    print(f\"ğŸ“Š Loading TensorBoard from: {latest_log}\")\n",
        "    %tensorboard --logdir {latest_log}\n",
        "else:\n",
        "    print(\"âš ï¸  No logs found. Did training complete?\")"
      ],
      "metadata": {
        "id": "tensorboard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ§ª Step 7: Test the Model\n",
        "\n",
        "Let's test the trained model on the test set."
      ],
      "metadata": {
        "id": "test-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best checkpoint\n",
        "import glob\n",
        "checkpoints = glob.glob('outputs/lucchi++_monai_unet/*/checkpoints/*.ckpt')\n",
        "\n",
        "if checkpoints:\n",
        "    # Get the most recent checkpoint\n",
        "    best_ckpt = max(checkpoints, key=os.path.getmtime)\n",
        "    print(f\"ğŸ” Found checkpoint: {best_ckpt}\\n\")\n",
        "    \n",
        "    # Run test\n",
        "    !python scripts/main.py \\\n",
        "        --config tutorials/monai_lucchi++.yaml \\\n",
        "        --mode test \\\n",
        "        --checkpoint {best_ckpt}\n",
        "else:\n",
        "    print(\"âš ï¸  No checkpoints found. Did training complete?\")"
      ],
      "metadata": {
        "id": "test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¨ Step 8: Visualize Predictions\n",
        "\n",
        "Let's visualize the model's predictions on test data."
      ],
      "metadata": {
        "id": "viz-pred-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load predictions and ground truth\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Find prediction file\n",
        "pred_files = glob.glob('outputs/lucchi++_monai_unet/results/test_im_prediction.h5')\n",
        "\n",
        "if pred_files:\n",
        "    pred_file = pred_files[0]\n",
        "    \n",
        "    # Load predictions and test data\n",
        "    with h5py.File(pred_file, 'r') as f:\n",
        "        predictions = f['main'][:]\n",
        "    \n",
        "    with h5py.File('datasets/Lucchi++/test_image.h5', 'r') as f:\n",
        "        test_image = f['main'][:]\n",
        "    \n",
        "    with h5py.File('datasets/Lucchi++/test_label.h5', 'r') as f:\n",
        "        test_label = f['main'][:]\n",
        "    \n",
        "    # Visualize multiple slices\n",
        "    num_slices = 3\n",
        "    fig, axes = plt.subplots(num_slices, 4, figsize=(16, num_slices * 4))\n",
        "    \n",
        "    for i in range(num_slices):\n",
        "        slice_idx = (i + 1) * test_image.shape[0] // (num_slices + 1)\n",
        "        \n",
        "        axes[i, 0].imshow(test_image[slice_idx], cmap='gray')\n",
        "        axes[i, 0].set_title(f'Input (slice {slice_idx})')\n",
        "        axes[i, 0].axis('off')\n",
        "        \n",
        "        axes[i, 1].imshow(test_label[slice_idx], cmap='gray')\n",
        "        axes[i, 1].set_title('Ground Truth')\n",
        "        axes[i, 1].axis('off')\n",
        "        \n",
        "        axes[i, 2].imshow(predictions[slice_idx], cmap='gray')\n",
        "        axes[i, 2].set_title('Prediction')\n",
        "        axes[i, 2].axis('off')\n",
        "        \n",
        "        # Overlay\n",
        "        axes[i, 3].imshow(test_image[slice_idx], cmap='gray')\n",
        "        axes[i, 3].imshow(predictions[slice_idx], cmap='Reds', alpha=0.4)\n",
        "        axes[i, 3].set_title('Overlay')\n",
        "        axes[i, 3].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Prediction Stats:\")\n",
        "    print(f\"  Predicted mitochondria: {(predictions > 0.5).sum() / predictions.size * 100:.1f}%\")\n",
        "    print(f\"  Ground truth: {(test_label > 0).sum() / test_label.size * 100:.1f}%\")\n",
        "else:\n",
        "    print(\"âš ï¸  No predictions found. Did testing complete?\")"
      ],
      "metadata": {
        "id": "viz-predictions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“ Next Steps\n",
        "\n",
        "Congratulations! You've successfully:\n",
        "- âœ… Installed PyTorch Connectomics\n",
        "- âœ… Trained a 3D U-Net\n",
        "- âœ… Tested on real data\n",
        "- âœ… Visualized results\n",
        "\n",
        "### Where to go from here?\n",
        "\n",
        "1. **Try different models:**\n",
        "   - MedNeXt (state-of-the-art)\n",
        "   - UNETR (transformer-based)\n",
        "   - Swin UNETR\n",
        "\n",
        "2. **Use your own data:**\n",
        "   - Upload HDF5/TIFF files\n",
        "   - Create custom config\n",
        "   - Train on your dataset\n",
        "\n",
        "3. **Optimize training:**\n",
        "   - Mixed precision (faster)\n",
        "   - Deep supervision (better)\n",
        "   - Advanced augmentations\n",
        "\n",
        "4. **Learn more:**\n",
        "   - ğŸ“š [Documentation](https://connectomics.readthedocs.io)\n",
        "   - ğŸ”§ [GitHub Repository](https://github.com/zudi-lin/pytorch_connectomics)\n",
        "   - ğŸ’¬ [Slack Community](https://join.slack.com/t/pytorchconnectomics/shared_invite/zt-obufj5d1-v5_NndNS5yog8vhxy4L12w)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¡ Tips for Colab\n",
        "\n",
        "- **Save checkpoints:** Download checkpoints before session expires\n",
        "- **Use Google Drive:** Mount Drive to save outputs persistently\n",
        "- **GPU limits:** Colab has usage limits, train in short sessions\n",
        "\n",
        "### ğŸ“ Feedback\n",
        "\n",
        "Found this helpful? Have suggestions? Let us know:\n",
        "- â­ Star us on [GitHub](https://github.com/zudi-lin/pytorch_connectomics)\n",
        "- ğŸ› Report issues\n",
        "- ğŸ’¬ Join our Slack community\n",
        "\n",
        "Happy segmenting! ğŸ”¬ğŸ§ "
      ],
      "metadata": {
        "id": "next-steps"
      }
    }
  ]
}
