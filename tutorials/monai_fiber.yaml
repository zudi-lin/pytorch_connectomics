# Fiber segmentation with MedNeXt
# Multi-task learning: Binary + Contour + Signed Distance Transform (BCS)
#
# This config uses MedNeXt for fiber segmentation with multi-task learning to predict:
#   - Channel 0: Binary fiber masks (sigmoid activation)
#   - Channel 1: Fiber contour/boundary maps (sigmoid activation)
#   - Channel 2: Signed distance transforms (tanh activation)
#
# Multi-task setup uses different loss functions for each channel:
#   - Binary: DiceLoss + BCEWithLogitsLoss
#   - Contour: DiceLoss + BCEWithLogitsLoss
#   - Distance: WeightedMSELoss (with tanh activation)
#
# Based on barcode-R-BCS.yaml configuration:
#   - 3 output channels (Binary + Contour + SDT)
#   - Loss weights: [1.0, 0.5] for Binary, [1.0, 0.5] for Contour, [4.0] for SDT
#   - Contour: instance boundary with thickness=1, edge_mode="all"
#   - SDT: affinity-based signed distance (a-0-40-16-16)

experiment_name: fiber_mednext_bcs
description: Fiber segmentation with MedNeXt and multi-task learning (Binary + Contour + SDT)

# System
system:
  training:
    num_gpus: 4                        # 4 GPU (
    num_cpus: 8                       # 16 CPUs for data loading
    num_workers: 8                     # Parallel data loading workers
    batch_size: 16                      # Batch size
  inference:
    num_gpus: 1
    num_cpus: 1
    num_workers: 1
    batch_size: 8                      # Inference batch size
  seed: 42

# Model - MedNeXt for multi-task fiber segmentation
model:  
  in_channels: 1                       # Single-channel grayscale EM images
  out_channels: 4                      # 4 outputs: Binary (2ch softmax) + Contour (1ch) + SDT (1ch)
  
  architecture: monai_unet
  input_size: [48, 128, 128]
  output_size: [48, 128, 128]
  filters: [28, 36, 48, 64, 80]      # Standard UNet channel progression
  num_res_units: 2                     # Residual units per block
  kernel_size: 3                       # Convolution kernel size
  norm: batch                          # Batch normalization
  dropout: 0.1                         # Dropout for regularization

  # Multi-task loss configuration (aligned with barcode-R-BCS.yaml)
  # Binary channel: DiceLoss + CrossEntropy with softmax (weights: 1.0, 0.5)
  # Contour channel: DiceLoss + BCEWithLogitsLoss with sigmoid (weights: 1.0, 0.5)
  # SDT channel: WeightedMSE (weight: 4.0)
  loss_functions: [DiceLoss, CrossEntropyLoss, DiceLoss, BCEWithLogitsLoss, WeightedMSE]
  loss_weights: [1.0, 0.5, 1.0, 0.5, 4.0]
  loss_kwargs:
    - {include_background: false, softmax: true, to_onehot_y: true, smooth_nr: 1e-5, smooth_dr: 1e-5}  # DiceLoss with softmax for binary
    - {label_smoothing: 0.1}             # CrossEntropyLoss for binary
    - {sigmoid: true, smooth_nr: 1e-5, smooth_dr: 1e-5}  # DiceLoss with sigmoid for contour
    - {}                                 # BCEWithLogitsLoss for contour
    - {tanh: true}                       # WeightedMSE for SDT (with tanh activation)

  # Multi-task configuration (matches barcode-R-BCS.yaml)
  # Format: [[start_ch, end_ch, target_name, loss_indices], ...]
  # Note: Output channels != Label channels for softmax tasks!
  # - Outputs use channels as specified below
  # - Labels always use 1 channel per task (label slicing handled automatically)
  multi_task_config:
    - [0, 2, "label", [0, 1]]          # Channels 0-1 (2 output channels): Binary with softmax (Dice + CrossEntropy)
    - [2, 3, "boundary", [2, 3]]       # Channel 2 (1 output channel): Contour with sigmoid (Dice + BCE)
    - [3, 4, "sdt", [4]]               # Channel 3 (1 output channel): SDT (WeightedMSE)

# Data - Fiber dataset configuration (based on barcode-R-Base.yaml)
data:
  # Base paths (NEW: will be combined with train_image/train_label)
  train_path: '/projects/weilab/dataset/barcode/train_r2/'

  # Volume configuration - TIFF files (barcode fiber structure)
  # Matches barcode-R dataset structure: ["1-xri_deconvolved.tif", "2-xri_deconvolved.tif"]
  # These paths will be combined with train_path above
  
  train_image: ["PT37/*_raw.tif", "CA1_LZ58/raw_p1-w2-CA1-8d-1-fiber-1.tif", "DG_LZ58/*-raw.tif"]
  train_label: ["PT37/*-mask.tif", "CA1_LZ58/final_p1-w2-CA1-8d-1-segmentation-1.tif", "DG_LZ58/*-mask.tif"]
  #train_image: ["DG_LZ58/0702-2-C4-DG-40X002_1-raw.tif"]
  #train_label: ["DG_LZ58/0702-2-C4-DG-40X002_1-mask.tif"]
   
  train_resolution: [40, 16, 16]   # Isotropic resolution (adjust based on actual data)
  use_preloaded_cache: true  
  persistent_workers: true            # Keep workers alive between epochs

  # Patch configuration (matches barcode-R-Base.yaml)
  patch_size: [48, 128, 128]            # Training patch size
  
  iter_num_per_epoch: 1000            # Iterations per epoch
  
  # Image normalization
  image_transform:
    normalize: "0-1"                   # Min-max normalization to [0, 1]
    clip_percentile_low: 0.005           # No clipping
    clip_percentile_high: 0.995
    pad_size: [8, 16, 16]              # Reflection padding for context
    pad_mode: reflect                   # Reflection padding at boundaries

  # Label transformation for multi-task learning (aligned with barcode-R-BCS.yaml)
  # TARGET_OPT: ["0", "4-0-1", "a-0-40-16-16"]
  label_transform:
    targets:
      - name: binary                   # Channel 0: Binary fiber mask
      - name: instance_boundary        # Channel 1: Contour map (4-0-1)
        kwargs:
          thickness: 1                 # thickness=1 (from "4-0-1")
          edge_mode: "seg-all"             # edge_mode="all" (from "4-0-1")
          mode: "2d"                   # 3D mode for volumetric data
      - name: skeleton_aware_edt       # Channel 2: Skeleton-aware EDT (a-0-40-16-16)
        kwargs:
          resolution: [40, 16, 16]     # Physical voxel resolution (z, y, x) from train_resolution
          alpha: 1                     # linear distance ratio
          smooth: false                 # Smooth distance transform
          smooth_skeleton_only: false   # Only smooth skeleton regions
          bg_value: -1.0               # Background value for distance map
          relabel: true                # Relabel connected components
          padding: false               # No padding

  # Augmentation Configuration with Presets
  # 
  # Choose a preset mode and set individual augmentations below:
  # 
  # Preset modes:
  #   - "all":  Start with ALL augmentations enabled by default
  #            (Manually set enabled: false to disable specific ones)
  #            WARNING: Requires use_preloaded_cache: true
  #   
  #   - "some": Start with NO augmentations, ONLY respect manually enabled ones
  #            (Manually set enabled: true to enable specific ones)
  #            RECOMMENDED: Safe and flexible
  #   
  #   - "none": Disable all augmentations completely
  #            (Individual settings ignored)
  #
  augmentation:
    preset: "some"  # Choose: "all", "some", or "none"
    flip:
      enabled: true
    rotate:
      enabled: true
      spatial_axes: [1, 2]  # Rotate only in Y-X plane (preserves Z-axis)
    affine:
      enabled: true                   # Affine transform (rotation + scaling + shearing)
      prob: 0.5                        # Probability of applying affine (0-1)
      rotate_range: [0.2, 0.2, 0.2]   # Rotation range in radians (~11° per axis)
      scale_range: [0.1, 0.1, 0.1]    # Scaling range (±10% per axis)
      shear_range: [0.1, 0.1, 0.1]    # Shearing range (±10° per axis)
    elastic:
      enabled: true
      prob: 0.3                      # Probability of applying elastic deformation (0-1)
      sigma_range: [8.0, 10.0]        # Gaussian filter sigma range for deformation field (in pixels)
      magnitude_range: [20.0, 50.0] # Deformation magnitude range (in pixels)
    intensity:
      enabled: true
      # Grayscale intensity augmentations (applied only to image, not labels)
      gaussian_noise_prob: 0             # Probability of adding Gaussian noise (0-1)      
      shift_intensity_prob: 0.3            # Probability of shifting intensity values (0-1)
      shift_intensity_offset: 0.1          # Intensity shift range as fraction of image range
      contrast_prob: 0.3                   # Probability of adjusting contrast (0-1)
      contrast_range: [0.7, 1.4]           # Contrast adjustment range (0.7 = darker, 1.4 = brighter)


# Optimizer - AdamW with cosine annealing (based on barcode-R-Base.yaml)
optimization:
  max_epochs: 1000                     # ~100k iterations / (1000 iters/epoch) = 100 epochs
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  precision: "16-mixed"                      # FP32 (debug: check if FP16 causes NaN)

  optimizer:
    name: AdamW
    lr: 0.002                           # BASE_LR: 0.02 (matches barcode-R-Base.yaml)
    weight_decay: 0.01
    betas: [0.9, 0.999]
    eps: 1.0e-8

  # Scheduler - Cosine annealing with warmup (matches barcode LR_SCHEDULER_NAME: WarmupCosineLR)
  scheduler:
    name: CosineAnnealingLR
    warmup_epochs: 5
    warmup_start_lr: 1.0e-5
    min_lr: 1.0e-6
    t_max: 995                         # max_epochs - warmup_epochs

monitor:
  # Loss monitoring and validation frequency
  detect_anomaly: false
  logging:
    # scalar loss
    scalar:
      loss: [train_loss_total_epoch]
      loss_every_n_steps: 10
      val_check_interval: 1.0
      benchmark: true

    # visualization
    images:
      enabled: true
      max_images: 2
      num_slices: 4
      log_every_n_epochs: 1            # Log less frequently for fiber data
      channel_mode: all                # Show all 3 channels for multi-task
      selected_channels: null

  # Checkpointing (matches barcode ITERATION_SAVE: 5000)
  checkpoint:
    mode: min
    save_top_k: 3
    save_last: true
    save_every_n_epochs: 50           # Save every 50 epochs (~50k iterations)
    use_timestamp: true

  # Early stopping
  early_stopping:
    enabled: true
    monitor: train_loss_total_epoch
    patience: 100                      # Patience in epochs
    mode: min
    min_delta: 1.0e-5
    check_finite: true
    threshold: 0.01
    divergence_threshold: 100.0

# Inference - MONAI SlidingWindowInferer for fiber segmentation (based on barcode-R-Base.yaml)
inference:
  data:
    # Test on all available volumes (matches barcode INFERENCE IMAGE_NAME)
    # Note: test_path will be combined with these relative paths
    test_path: "/projects/weilab/dataset/barcode/train_r2/"
    test_image: ["DG_LZ58/0702-2-C4-DG-40X002_1-raw.tif"]
    test_label: ["DG_LZ58/0702-2-C4-DG-40X002_1-mask.tif"]
    test_resolution: [40, 16, 16]   # Isotropic resolution
    # Output filename (auto-pathed based on the checkpoint folder)
    output_name: DG_train.h5

  # MONAI SlidingWindowInferer parameters (matches barcode INFERENCE)
  sliding_window:
    window_size: [48, 128, 128]        # INPUT_SIZE/OUTPUT_SIZE (barcode-R-Base.yaml)
    stride: [24, 64, 64]             # STRIDE (barcode-R-Base.yaml)
    blending: gaussian                 # Gaussian weighting for smooth blending
    sigma_scale: 0.25
    padding_mode: reflect              # Reflection-padding at volume boundaries
    pad_size: [16, 32, 32]             # PAD_SIZE (matches barcode-R-Base.yaml)

  # Test-Time Augmentation (TTA) - matches barcode AUG_MODE: "mean"
  test_time_augmentation:
    enabled: true
    flip_axes: null                    # Use all flip augmentations (AUG_NUM: None)
    # Per-channel activations (aligned with barcode-R-BCS.yaml OUTPUT_ACT)
    # OUTPUT_ACT: ["softmax", "sigmoid", "tanh"]
    # Format: [[start_ch, end_ch, activation], ...]
    channel_activations:
      - [0, 2, softmax]                # Channels 0-1: binary fiber mask (softmax over 2 classes)
      - [2, 3, sigmoid]                # Channel 2: contour
      - [3, 4, tanh]                   # Channel 3: SDT
    select_channel: [1,2,3]
    ensemble_mode: mean                # AUG_MODE: "mean"

  # Decoding configuration (instance segmentation postprocessing)
  decoding:
    - name: decode_binary_contour_distance_watershed
      kwargs:
        binary_threshold: [0.9, 0.85]
        contour_threshold: [0.8, 1.1]
        distance_threshold: [0.5, -0.5]
        min_instance_size: 100         # Larger fibers (adjust based on data)
        min_seed_size: 20
        prediction_scale: 1

  # Evaluation
  evaluation:
    enabled: true
    metrics: [adapted_rand]
